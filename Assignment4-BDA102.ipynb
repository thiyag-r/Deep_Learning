{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, use a linear activation function within the keras library to create a regression-based neural network. \n",
    "Essentially, we are trying to predict the value of a potential car sale (i.e. how much a particular person will spend on buying a car) for a customer based on the following attributes:\n",
    "\n",
    "-Age\n",
    "\n",
    "-Gender\n",
    "\n",
    "-Average miles driven per day\n",
    "\n",
    "-Personal debt\n",
    "\n",
    "-Monthly income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\santh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "dataset=pd.read_csv('C:/Users/santh/Downloads/cars.csv')\n",
    "x=dataset.iloc[:,0:5]\n",
    "y=dataset.iloc[:,5]\n",
    "y = array(y)\n",
    "y=np.reshape(y, (-1,1))\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(x))\n",
    "print(scaler.fit(y))\n",
    "xscale=scaler.transform(x)\n",
    "yscale=scaler.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\santh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile/fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\santh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/150\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.2191 - mean_squared_error: 0.2191 - mean_absolute_error: 0.3617 - val_loss: 0.1797 - val_mean_squared_error: 0.1797 - val_mean_absolute_error: 0.3231\n",
      "Epoch 2/150\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.1858 - mean_squared_error: 0.1858 - mean_absolute_error: 0.3241 - val_loss: 0.1503 - val_mean_squared_error: 0.1503 - val_mean_absolute_error: 0.2882\n",
      "Epoch 3/150\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.1540 - mean_squared_error: 0.1540 - mean_absolute_error: 0.2916 - val_loss: 0.1201 - val_mean_squared_error: 0.1201 - val_mean_absolute_error: 0.2575\n",
      "Epoch 4/150\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.1187 - mean_squared_error: 0.1187 - mean_absolute_error: 0.2629 - val_loss: 0.0885 - val_mean_squared_error: 0.0885 - val_mean_absolute_error: 0.2316\n",
      "Epoch 5/150\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.0875 - mean_squared_error: 0.0875 - mean_absolute_error: 0.2407 - val_loss: 0.0662 - val_mean_squared_error: 0.0662 - val_mean_absolute_error: 0.2163\n",
      "Epoch 6/150\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.0665 - mean_squared_error: 0.0665 - mean_absolute_error: 0.2236 - val_loss: 0.0538 - val_mean_squared_error: 0.0538 - val_mean_absolute_error: 0.2066\n",
      "Epoch 7/150\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.0537 - mean_squared_error: 0.0537 - mean_absolute_error: 0.2080 - val_loss: 0.0471 - val_mean_squared_error: 0.0471 - val_mean_absolute_error: 0.1956\n",
      "Epoch 8/150\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.0461 - mean_squared_error: 0.0461 - mean_absolute_error: 0.1943 - val_loss: 0.0438 - val_mean_squared_error: 0.0438 - val_mean_absolute_error: 0.1867\n",
      "Epoch 9/150\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.0420 - mean_squared_error: 0.0420 - mean_absolute_error: 0.1840 - val_loss: 0.0410 - val_mean_squared_error: 0.0410 - val_mean_absolute_error: 0.1784\n",
      "Epoch 10/150\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.0383 - mean_squared_error: 0.0383 - mean_absolute_error: 0.1741 - val_loss: 0.0377 - val_mean_squared_error: 0.0377 - val_mean_absolute_error: 0.1707\n",
      "Epoch 11/150\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.0346 - mean_squared_error: 0.0346 - mean_absolute_error: 0.1643 - val_loss: 0.0350 - val_mean_squared_error: 0.0350 - val_mean_absolute_error: 0.1637\n",
      "Epoch 12/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0315 - mean_squared_error: 0.0315 - mean_absolute_error: 0.1556 - val_loss: 0.0324 - val_mean_squared_error: 0.0324 - val_mean_absolute_error: 0.1567\n",
      "Epoch 13/150\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.0288 - mean_squared_error: 0.0288 - mean_absolute_error: 0.1478 - val_loss: 0.0306 - val_mean_squared_error: 0.0306 - val_mean_absolute_error: 0.1504\n",
      "Epoch 14/150\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.0267 - mean_squared_error: 0.0267 - mean_absolute_error: 0.1407 - val_loss: 0.0291 - val_mean_squared_error: 0.0291 - val_mean_absolute_error: 0.1448\n",
      "Epoch 15/150\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.0250 - mean_squared_error: 0.0250 - mean_absolute_error: 0.1350 - val_loss: 0.0280 - val_mean_squared_error: 0.0280 - val_mean_absolute_error: 0.1403\n",
      "Epoch 16/150\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.0238 - mean_squared_error: 0.0238 - mean_absolute_error: 0.1307 - val_loss: 0.0273 - val_mean_squared_error: 0.0273 - val_mean_absolute_error: 0.1366\n",
      "Epoch 17/150\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.0228 - mean_squared_error: 0.0228 - mean_absolute_error: 0.1270 - val_loss: 0.0267 - val_mean_squared_error: 0.0267 - val_mean_absolute_error: 0.1343\n",
      "Epoch 18/150\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.0223 - mean_squared_error: 0.0223 - mean_absolute_error: 0.1244 - val_loss: 0.0263 - val_mean_squared_error: 0.0263 - val_mean_absolute_error: 0.1320\n",
      "Epoch 19/150\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.0218 - mean_squared_error: 0.0218 - mean_absolute_error: 0.1228 - val_loss: 0.0263 - val_mean_squared_error: 0.0263 - val_mean_absolute_error: 0.1321\n",
      "Epoch 20/150\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.0214 - mean_squared_error: 0.0214 - mean_absolute_error: 0.1213 - val_loss: 0.0259 - val_mean_squared_error: 0.0259 - val_mean_absolute_error: 0.1298\n",
      "Epoch 21/150\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.0211 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1191 - val_loss: 0.0257 - val_mean_squared_error: 0.0257 - val_mean_absolute_error: 0.1282\n",
      "Epoch 22/150\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.0207 - mean_squared_error: 0.0207 - mean_absolute_error: 0.1183 - val_loss: 0.0257 - val_mean_squared_error: 0.0257 - val_mean_absolute_error: 0.1286\n",
      "Epoch 23/150\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.0204 - mean_squared_error: 0.0204 - mean_absolute_error: 0.1173 - val_loss: 0.0254 - val_mean_squared_error: 0.0254 - val_mean_absolute_error: 0.1272\n",
      "Epoch 24/150\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.0201 - mean_squared_error: 0.0201 - mean_absolute_error: 0.1158 - val_loss: 0.0252 - val_mean_squared_error: 0.0252 - val_mean_absolute_error: 0.1264\n",
      "Epoch 25/150\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.0199 - mean_squared_error: 0.0199 - mean_absolute_error: 0.1147 - val_loss: 0.0251 - val_mean_squared_error: 0.0251 - val_mean_absolute_error: 0.1253\n",
      "Epoch 26/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0196 - mean_squared_error: 0.0196 - mean_absolute_error: 0.1136 - val_loss: 0.0250 - val_mean_squared_error: 0.0250 - val_mean_absolute_error: 0.1254\n",
      "Epoch 27/150\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.0194 - mean_squared_error: 0.0194 - mean_absolute_error: 0.1132 - val_loss: 0.0249 - val_mean_squared_error: 0.0249 - val_mean_absolute_error: 0.1244\n",
      "Epoch 28/150\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.0192 - mean_squared_error: 0.0192 - mean_absolute_error: 0.1114 - val_loss: 0.0246 - val_mean_squared_error: 0.0246 - val_mean_absolute_error: 0.1229\n",
      "Epoch 29/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0189 - mean_squared_error: 0.0189 - mean_absolute_error: 0.1103 - val_loss: 0.0246 - val_mean_squared_error: 0.0246 - val_mean_absolute_error: 0.1230\n",
      "Epoch 30/150\n",
      "576/576 [==============================] - 0s 7us/step - loss: 0.0188 - mean_squared_error: 0.0188 - mean_absolute_error: 0.1106 - val_loss: 0.0246 - val_mean_squared_error: 0.0246 - val_mean_absolute_error: 0.1234\n",
      "Epoch 31/150\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.0185 - mean_squared_error: 0.0185 - mean_absolute_error: 0.1092 - val_loss: 0.0243 - val_mean_squared_error: 0.0243 - val_mean_absolute_error: 0.1212\n",
      "Epoch 32/150\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.0184 - mean_squared_error: 0.0184 - mean_absolute_error: 0.1076 - val_loss: 0.0242 - val_mean_squared_error: 0.0242 - val_mean_absolute_error: 0.1205\n",
      "Epoch 33/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0183 - mean_squared_error: 0.0183 - mean_absolute_error: 0.1079 - val_loss: 0.0243 - val_mean_squared_error: 0.0243 - val_mean_absolute_error: 0.1214\n",
      "Epoch 34/150\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.0180 - mean_squared_error: 0.0180 - mean_absolute_error: 0.1068 - val_loss: 0.0241 - val_mean_squared_error: 0.0241 - val_mean_absolute_error: 0.1197\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 38us/step - loss: 0.0179 - mean_squared_error: 0.0179 - mean_absolute_error: 0.1059 - val_loss: 0.0241 - val_mean_squared_error: 0.0241 - val_mean_absolute_error: 0.1198\n",
      "Epoch 36/150\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.0177 - mean_squared_error: 0.0177 - mean_absolute_error: 0.1049 - val_loss: 0.0239 - val_mean_squared_error: 0.0239 - val_mean_absolute_error: 0.1185\n",
      "Epoch 37/150\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.0177 - mean_squared_error: 0.0177 - mean_absolute_error: 0.1043 - val_loss: 0.0240 - val_mean_squared_error: 0.0240 - val_mean_absolute_error: 0.1190\n",
      "Epoch 38/150\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.0175 - mean_squared_error: 0.0175 - mean_absolute_error: 0.1032 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1173\n",
      "Epoch 39/150\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.0174 - mean_squared_error: 0.0174 - mean_absolute_error: 0.1025 - val_loss: 0.0238 - val_mean_squared_error: 0.0238 - val_mean_absolute_error: 0.1175\n",
      "Epoch 40/150\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0168 - mean_absolute_error: 0.10 - 0s 31us/step - loss: 0.0173 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1020 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1171\n",
      "Epoch 41/150\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.0172 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1016 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1171\n",
      "Epoch 42/150\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.0171 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1016 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1165\n",
      "Epoch 43/150\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.0170 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1000 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1150\n",
      "Epoch 44/150\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.0170 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1003 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1158\n",
      "Epoch 45/150\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.0168 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0993 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1151\n",
      "Epoch 46/150\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.0167 - mean_squared_error: 0.0167 - mean_absolute_error: 0.0985 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1143\n",
      "Epoch 47/150\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.0167 - mean_squared_error: 0.0167 - mean_absolute_error: 0.0980 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1144\n",
      "Epoch 48/150\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.0166 - mean_squared_error: 0.0166 - mean_absolute_error: 0.0977 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1143\n",
      "Epoch 49/150\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.0165 - mean_squared_error: 0.0165 - mean_absolute_error: 0.0977 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1148\n",
      "Epoch 50/150\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.0165 - mean_squared_error: 0.0165 - mean_absolute_error: 0.0977 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1140\n",
      "Epoch 51/150\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.0165 - mean_squared_error: 0.0165 - mean_absolute_error: 0.0967 - val_loss: 0.0233 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1131\n",
      "Epoch 52/150\n",
      "576/576 [==============================] - 0s 12us/step - loss: 0.0164 - mean_squared_error: 0.0164 - mean_absolute_error: 0.0971 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1141\n",
      "Epoch 53/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0164 - mean_squared_error: 0.0164 - mean_absolute_error: 0.0960 - val_loss: 0.0233 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1128\n",
      "Epoch 54/150\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.0163 - mean_squared_error: 0.0163 - mean_absolute_error: 0.0959 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1136\n",
      "Epoch 55/150\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.0162 - mean_squared_error: 0.0162 - mean_absolute_error: 0.0955 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1128\n",
      "Epoch 56/150\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.0162 - mean_squared_error: 0.0162 - mean_absolute_error: 0.0954 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1127\n",
      "Epoch 57/150\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.0161 - mean_squared_error: 0.0161 - mean_absolute_error: 0.0950 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1127\n",
      "Epoch 58/150\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.0161 - mean_squared_error: 0.0161 - mean_absolute_error: 0.0948 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1127\n",
      "Epoch 59/150\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.0161 - mean_squared_error: 0.0161 - mean_absolute_error: 0.0946 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1123\n",
      "Epoch 60/150\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.0161 - mean_squared_error: 0.0161 - mean_absolute_error: 0.0946 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1126\n",
      "Epoch 61/150\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.0160 - mean_squared_error: 0.0160 - mean_absolute_error: 0.0944 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1119\n",
      "Epoch 62/150\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.0160 - mean_squared_error: 0.0160 - mean_absolute_error: 0.0940 - val_loss: 0.0233 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1115\n",
      "Epoch 63/150\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.0160 - mean_squared_error: 0.0160 - mean_absolute_error: 0.0938 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1118\n",
      "Epoch 64/150\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.0160 - mean_squared_error: 0.0160 - mean_absolute_error: 0.0937 - val_loss: 0.0233 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1116\n",
      "Epoch 65/150\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.0160 - mean_squared_error: 0.0160 - mean_absolute_error: 0.0939 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1122\n",
      "Epoch 66/150\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.0160 - mean_squared_error: 0.0160 - mean_absolute_error: 0.0939 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1119\n",
      "Epoch 67/150\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0934 - val_loss: 0.0233 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1110\n",
      "Epoch 68/150\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0932 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1116\n",
      "Epoch 69/150\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0932 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1114\n",
      "Epoch 70/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 32us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0931 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1115\n",
      "Epoch 71/150\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0932 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1112\n",
      "Epoch 72/150\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0928 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1111\n",
      "Epoch 73/150\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0928 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1111\n",
      "Epoch 74/150\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0926 - val_loss: 0.0233 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1106\n",
      "Epoch 75/150\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0925 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1110\n",
      "Epoch 76/150\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0928 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1117\n",
      "Epoch 77/150\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0925 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1106\n",
      "Epoch 78/150\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0923 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1107\n",
      "Epoch 79/150\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0922 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1109\n",
      "Epoch 80/150\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0921 - val_loss: 0.0233 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1103\n",
      "Epoch 81/150\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0923 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1110\n",
      "Epoch 82/150\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0922 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1105\n",
      "Epoch 83/150\n",
      "576/576 [==============================] - 0s 15us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0921 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1111\n",
      "Epoch 84/150\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0919 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1109\n",
      "Epoch 85/150\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0922 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1111\n",
      "Epoch 86/150\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0918 - val_loss: 0.0233 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1105\n",
      "Epoch 87/150\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0918 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1110\n",
      "Epoch 88/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0917 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1104\n",
      "Epoch 89/150\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0918 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1109\n",
      "Epoch 90/150\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0916 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1107\n",
      "Epoch 91/150\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0915 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1110\n",
      "Epoch 92/150\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0915 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1108\n",
      "Epoch 93/150\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0922 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1110\n",
      "Epoch 94/150\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0916 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1111\n",
      "Epoch 95/150\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0918 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1110\n",
      "Epoch 96/150\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0915 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1115\n",
      "Epoch 97/150\n",
      "576/576 [==============================] - 0s 13us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0913 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1107\n",
      "Epoch 98/150\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0914 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1109\n",
      "Epoch 99/150\n",
      "576/576 [==============================] - 0s 8us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0920 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1109\n",
      "Epoch 100/150\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0918 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1103\n",
      "Epoch 101/150\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.0159 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0927 - val_loss: 0.0239 - val_mean_squared_error: 0.0239 - val_mean_absolute_error: 0.1121\n",
      "Epoch 102/150\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0912 - val_loss: 0.0233 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1101\n",
      "Epoch 103/150\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0917 - val_loss: 0.0238 - val_mean_squared_error: 0.0238 - val_mean_absolute_error: 0.1119\n",
      "Epoch 104/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0915 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1108\n",
      "Epoch 105/150\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0913 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150\n",
      "576/576 [==============================] - 0s 14us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0914 - val_loss: 0.0238 - val_mean_squared_error: 0.0238 - val_mean_absolute_error: 0.1120\n",
      "Epoch 107/150\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0911 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1102\n",
      "Epoch 108/150\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0909 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1105\n",
      "Epoch 109/150\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0912 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1111\n",
      "Epoch 110/150\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0909 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1105\n",
      "Epoch 111/150\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0909 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1106\n",
      "Epoch 112/150\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0908 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1107\n",
      "Epoch 113/150\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0913 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1106\n",
      "Epoch 114/150\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0908 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1104\n",
      "Epoch 115/150\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0908 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1109\n",
      "Epoch 116/150\n",
      "576/576 [==============================] - 0s 20us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0910 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1110\n",
      "Epoch 117/150\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0910 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1105\n",
      "Epoch 118/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0909 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1111\n",
      "Epoch 119/150\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0914 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1109\n",
      "Epoch 120/150\n",
      "576/576 [==============================] - 0s 19us/step - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0913 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1107\n",
      "Epoch 121/150\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0915 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1111\n",
      "Epoch 122/150\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0908 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1108\n",
      "Epoch 123/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0916 - val_loss: 0.0238 - val_mean_squared_error: 0.0238 - val_mean_absolute_error: 0.1112\n",
      "Epoch 124/150\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0907 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1103\n",
      "Epoch 125/150\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0911 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1112\n",
      "Epoch 126/150\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0908 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1108\n",
      "Epoch 127/150\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0914 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1103\n",
      "Epoch 128/150\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0909 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1109\n",
      "Epoch 129/150\n",
      "576/576 [==============================] - 0s 23us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0911 - val_loss: 0.0238 - val_mean_squared_error: 0.0238 - val_mean_absolute_error: 0.1112\n",
      "Epoch 130/150\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0905 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1103\n",
      "Epoch 131/150\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0912 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1108\n",
      "Epoch 132/150\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0906 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1108\n",
      "Epoch 133/150\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0911 - val_loss: 0.0239 - val_mean_squared_error: 0.0239 - val_mean_absolute_error: 0.1116\n",
      "Epoch 134/150\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0906 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1104\n",
      "Epoch 135/150\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0906 - val_loss: 0.0238 - val_mean_squared_error: 0.0238 - val_mean_absolute_error: 0.1112\n",
      "Epoch 136/150\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0907 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1106\n",
      "Epoch 137/150\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0908 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1112\n",
      "Epoch 138/150\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0918 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1108\n",
      "Epoch 139/150\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0910 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_mean_absolute_error: 0.1106\n",
      "Epoch 140/150\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0908 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1111\n",
      "Epoch 141/150\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0908 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/150\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0907 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1111\n",
      "Epoch 143/150\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0912 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1108\n",
      "Epoch 144/150\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0908 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1106\n",
      "Epoch 145/150\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0906 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1111\n",
      "Epoch 146/150\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0909 - val_loss: 0.0238 - val_mean_squared_error: 0.0238 - val_mean_absolute_error: 0.1111\n",
      "Epoch 147/150\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0908 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1107\n",
      "Epoch 148/150\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0908 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1109\n",
      "Epoch 149/150\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0906 - val_loss: 0.0236 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1105\n",
      "Epoch 150/150\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.0157 - mean_squared_error: 0.0157 - mean_absolute_error: 0.0913 - val_loss: 0.0239 - val_mean_squared_error: 0.0239 - val_mean_absolute_error: 0.1114\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "Fitting = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = np.array([[40, 0, 26, 9000, 8000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict the new set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[  40.    0.   26. 9000. 8000.], Predicted=[13526.144]\n"
     ]
    }
   ],
   "source": [
    "Xnew= scaler.transform(Xnew)\n",
    "ynew= model.predict(Xnew)\n",
    "#invert normalize\n",
    "ynew = scaler.inverse_transform(ynew) \n",
    "Xnew = scaler.inverse_transform(Xnew)\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
